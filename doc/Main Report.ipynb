{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 4 Causal Inference Report\n",
    "## Group 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Project Overview\n",
    "\n",
    "Propensity scores addresses selection bias from observational data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Data Preparation\n",
    "### 2.1 Load Required Packages\n",
    "\n",
    "\"Y\" indicates the outcome variable, \"A\" is the treatment group assignment, and there are 22 covariates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import seaborn as sns\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# setting graph styles\n",
    "sns.set(rc={'figure.figsize':(10,8)})\n",
    "#sns.set_theme(style='ticks') broken\n",
    "\n",
    "# set seed\n",
    "random_state = 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load high dimensional data\n",
    "highdim_data = pd.read_csv('../data/highDim_dataset.csv')\n",
    "\n",
    "# load low dimensional data\n",
    "lowdim_data = pd.read_csv('../data/lowDim_dataset.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The high dimensional data has\",highdim_data.shape[0],\"observations and\", highdim_data.shape[1], \"variables.\")\n",
    "print(\"The low dimensional data has\",lowdim_data.shape[0],\"observations and\", lowdim_data.shape[1], \"variables.\")\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize outcome values on high dimensional data by treatment group\n",
    "sns.violinplot(x=\"A\", y=\"Y\", data=highdim_data)\n",
    "plt.title('High Dimensional Data - Outcome values by Treatment Group', size=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize outcome values on low dimensional data by treatment group\n",
    "sns.violinplot(x=\"A\", y=\"Y\", data=lowdim_data)\n",
    "plt.title('Low Dimensional Data - Outcome values by Treatment Group', size=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Propensity Scores Estimation and Evaluation\n",
    "We will use L1 penalized logistic regression to estimate propensity scores for both data sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Create Propensity Score Estimation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function to tune for best hyperparameters for each data set\n",
    "\n",
    "def best_param(data, random_state, param_grid, cv=10):\n",
    "    '''\n",
    "    Purpose: to find the best parameter \"C\" (coefficient of regularization strength) for the specific dataset\n",
    "    \n",
    "    Parameters:\n",
    "    data - dataset to best tested on \n",
    "    random_state - set seed\n",
    "    param_grid - set of parameter values to test on\n",
    "    cv - number of folds for cross-validation\n",
    "    \n",
    "    '''\n",
    "\n",
    "    x = data.drop(['A','Y'], axis = 1)  \n",
    "    y = data[['A']].values.ravel()\n",
    "    \n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=random_state)\n",
    "    \n",
    "    \n",
    "    model_cv = GridSearchCV(LogisticRegression(penalty='l1',solver = 'liblinear'), param_grid, cv=cv)\n",
    "    model_cv.fit(x_train, y_train)\n",
    "    \n",
    "    print(\"The best tuned coefficient of regularization strength is\",model_cv.best_params_.get('C'), \n",
    "          \"with a testing accuracy of\", model_cv.score(x_test, y_test))\n",
    "    \n",
    "    return model_cv.best_params_.get('C')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def propensity_score(data, C=0.1, plot = True):\n",
    "    '''\n",
    "    Purpose: to estimate propensity score with L1 penalized logistic regression\n",
    "    \n",
    "    Parameters:\n",
    "    data - dataset to estimate on \n",
    "    C - coeficient of regularization strength\n",
    "    plot - print out visualization to show distribution of propensity scores\n",
    "    \n",
    "    Returns:\n",
    "    1. ps for Propensity Score\n",
    "    2. Visualization plot to show distribution of propensity scores\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    T = 'A'\n",
    "    Y = 'Y'\n",
    "    X = data.columns.drop([T,Y])\n",
    "    \n",
    "    ps_model = LogisticRegression(random_state=random_state, penalty='l1',\n",
    "                                  solver='liblinear').fit(data[X], data[T]) \n",
    "    \n",
    "    ps = ps_model.predict_proba(data[X])[:,1] # we are interested in the probability of getting a \"1\"\n",
    "    \n",
    "    plot = FALSE\n",
    "    \n",
    "    if plot:\n",
    "        df_plot = pd.DataFrame({'Treatment':data[T], 'Propensity Score':ps})\n",
    "        \n",
    "        sns.histplot(data=df_plot, x = \"Propensity Score\", hue = \"Treatment\", element = \"step\")\n",
    "        plt.title(\"Distribution of Propensity Score by Treatment Group\", size=20)\n",
    "        plt.show()\n",
    "   \n",
    "    return ps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting parameters\n",
    "param_grid = {\"C\":[0.01,0.05,0.1,0.3,0.5,0.7,1]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Evaluate Propensity Scores for High Dimensional Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use 10-fold cross-validation to tune for the best parameter for logistic regression\n",
    "c_high = best_param(highdim_data, random_state=random_state, param_grid=param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimate propsensity scores\n",
    "ps_high = propensity_score(highdim_data, C = c_high)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Evaluate Propensity Scores for Low Dimensional Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use 10-fold cross-validation to tune for the best parameter for logistic regression\n",
    "c_low = best_param(lowdim_data, random_state=random_state, param_grid=param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ps_low = propensity_score(lowdim_data, C = c_low)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Algorithm Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Stratification\n",
    "\n",
    "def stratification(data, prop):\n",
    "    start = time.time()\n",
    "    K = 5 # k, quintiles is reccomended\n",
    "   # N = len(df.index)\n",
    "    strata = [1,2,3,4,5]\n",
    "    ATE = 0\n",
    "\n",
    "    #split propensity scores into thier respective quintiles \n",
    "    prop_split = pd.qcut(prop, K)\n",
    "    prop_split.categories = strata \n",
    "    \n",
    "    \n",
    "    #label the dataset and group accordingly\n",
    "    quintiles = copy.copy(data)\n",
    "    quintiles[\"strata\"] = prop_split\n",
    "    quintiles = quintiles[[\"A\", \"strata\", \"Y\"]]\n",
    "\n",
    "    #calucate the average Y\n",
    "    quintiles = quintiles.groupby([\"A\", \"strata\"]).mean\n",
    "\n",
    "    for num in strata:\n",
    "        ATE += quintiles.loc[pd.IndexSlice[(1, num)]] - quintiles.loc[pd.IndexSlice[(0, num)]] \n",
    "    \n",
    "    #Divide by k\n",
    "    ATE = ATE/K\n",
    "\n",
    "    end = time.time()\n",
    "\n",
    "    print(\"Estamated ATE: \", round(ATE.values[0], 2))\n",
    "    print(\"Runtime: \", end-start)\n",
    "\n",
    "    return(ATE, end-start)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 Run Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrueATEhi = -54.8558\n",
    "TrueATElo = 2.0901\n",
    "\n",
    "print(\"low\")\n",
    "loATE = stratification(lowdim_data, prop)[0]\n",
    "precentdifflo = (TrueATElo - loATE)/TrueATElo\n",
    "\n",
    "Print(\"the Accuracy is \", precentdifflo)\n",
    "\n",
    "\n",
    "print(\"high\")\n",
    "hiATE = stratification(highdim_data, prop)[0]\n",
    "precentdiffhi = (TrueATEhi - hiATE)/TrueATEhi\n",
    "\n",
    "Print(\"the Accuracy is \", precentdiffhi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.6 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "ecf149c49bd9faca87549bf50cd58cd1aec88c35cf87480148fff05c971e8f18"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}